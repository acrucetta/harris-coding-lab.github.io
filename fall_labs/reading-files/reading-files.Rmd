---
title: "Reading Files"
output: 
  html_notebook:
    toc: true
    toc_float: true
---

## Warm up

1. Which of these are commands from `dplyr`?

- mutate()
- filter()
- mean()
- group_by()

2. In the videos, you learned about `head()`. What if you wanted to get the tail end of your data instead?

3. Imagine you have a data set, `df` with 4 variables, `county`, `year`, `income`, and `employment`. You only need the year and employment status of people whose income is below $5000. Which two `dplyr` commands do you need to do this? Can you write the code for this?

4. Remember the `mean()` function from last time? What `dplyr` commands would we need if we want the average income in each county for each year? How many rows will the resulting dataset be?

## Analyzing Student Loan Debt

### Data Cleaning

We've provided a clean dataset of student loan data for you for this assignment, along with this R Markdown file. Before you start, check the data folder make sure you have the student loan Excel dataset, `"area_report_by_year.xlsx"`. The clean version is `"student_loan_debt.csv"`.

The original student loan data looks like this:

**Note**: A sample header and value have been highlighted in orange for you to follow how the data changes as we restructure it. Also, you can see from the line below that inserting images in your notebooks is super easy! Go ahead, insert your favorite meme (but not in an actual class assignment)!

![](images/01_excel.jpg)

Here's the code we wrote to clean our data. We're including it here so you can see what our data prep looks like, but we don't expect you to know all of the functions in here yet! (You'll learn more about a few of them in a bit.)

**Note**: Each of these statements is separated by the "pipe", or `%>%`, which you can read as the word "then". Read the Excel file, *then* filter values, *then* transform the data... 

```{r clean, eval=FALSE}
library(tidyverse)
library(readxl)

student_loan_debt <- read_xlsx("data/area_report_by_year.xlsx", sheet = "studentloan", skip = 3) %>%
  filter(state != "allUS") %>%
  gather(key = year, value = per_capita_student_debt, -state) %>% 
  mutate(year = str_sub(year, 4, 7),
         year = as.numeric(year))

write_csv(student_loan_debt, "student_loan_debt.csv")
```

What's going on here? 

```{r clean0, eval=FALSE}
library(tidyverse)
library(readxl)
```

0. We **load the packages** that have the functions we need: `tidyverse` and `readxl`.

```{r clean1, eval=FALSE}
student_loan_debt <- read_xlsx("data/area_report_by_year.xlsx", sheet = "studentloan", skip = 3) 
```

1. We tell our `read_xlsx` function to go to the `data` folder where we have the data, then to `"area_report_by_year.xlsx"`, so that it can find the data. We specify the sheet in the Excel workbook we want to read, and we skip the first 3 rows in the sheet, because the data we're interested in starts on line 4. The resulting data looks like this:

![](images/02_wide.jpg)

**Note:** R sets as a working directory (think of it as a root folder) the folder where this R Markdown script is located. In this case, because you unzipped the folder we gave you, we know that wherever this folder is in your computer, there's a `data` folder in it, and the Excel spreadsheet is in it. 

This means that R looks for files *relative* to the current working directory. You could also give R an *absolute* file path, such as: `"Users/John Smith/Dropbox/Coding Lab/reading-files/data/area_report_by_year.xlsx"`. 

However, note that this absolute path wouldn't work in someone else's computer, and also wouldn't work if John decides to move his Coding Lab files elsewhere, while the relative path will work just fine.

Sometimes, you want to set another working directory. If you're writing a regular R script, you can use the `setwd()` command to change it. If you're in an R Markdown file like this one, you need to use a setup code chunk like the following:

```{r, setup, eval=FALSE}
knitr::opts_knit$set(root.dir = "")
```

Where your directory goes where the quotation marks are.

**One more thing on this:** To quickly find a file path, select a folder or file on OS X and press Cmd + Alt + C to copy the full path to your clipboard. On Windows, hold Shift, then right click the file or folder, then select "Copy as Path". A small caveat is that on Windows you'll get backslashes instead of forward slashes, which R will not enjoy. There are several ways to fix this, ranging from a simple Ctrl + F replace to much fancier solutions. Google is your friend. The Mac shortcut works right away.

Ok, digression over. Let's continue cleaning the data:

```{r clean2, eval=FALSE}
filter(state != "allUS")
```

2. We **filter out rows of data** that are for the entire US, leaving only rows that refer to states.

```{r clean3, eval=FALSE}
gather(key = year, value = per_capita_student_debt, -state)
```

3. We **convert the data from a wide to a long format**, so that `year` is a variable and `per_capita_student_debt` is also a variable. (The reason we do this is so that it is easier for functions in the "tidyverse" to process this type of data for groupwise calculations, e.g. mean debt by year, etc. Read more about [tidy data](https://r4ds.had.co.nz/tidy-data.html#introduction-6) in R for Data Science.)

![](images/03_long.jpg)

```{r clean4, eval=FALSE}
mutate(year = str_sub(year, 4, 7),
       year = as.numeric(year))
```

4. We use **string manipulation** to modify the existing `year` column, and then we **convert the type** of the column.

![](images/04_final.jpg)

What was the original type of the `year` column? What is the new type of the `year` column?

```{r clean5, eval=FALSE}
write_csv(student_loan_debt, "student_loan_debt.csv")
```

5. We **write the cleaned data to a CSV** (comma-separated variables file).

Try running this code locally on your computer! Copy the code to a new script, and save it to the same folder that you've stored your downloaded data in. Make sure to set your new folder as your "working directory" correctly.

## Exploratory Data Analysis

Ok, now that we've gone over how the file was created, load the cleaned data in your own R session:

```{r data-load}
library(readr)
library(dplyr)

student_loan_debt <- read_csv(___)
```

To look at your data after reading it in, you can use a `tidyverse` function called `glimpse()`. This is a nicer version of a function called `str()`. Try running both `str()` and `glimpse()` on `student_loan_debt`.

**Note**: `student_loan_debt` can be long to type, so use **Tab-Autocomplete**. Once you start typing the variable in the function, press **Tab** and wait for the variable name to automatically pop up. Press **Enter** to fill in `student_loan_debt` (or click on it).

```{r}

```

### Arranging Data

We can use the `arrange()` function from `dplyr` to sort the student loan data. The syntax is `arrange(data, variable)`. Arrange the data in `student_loan_debt` by `per_capita_student_debt`. (Can you sort the other way?)

```{r arrange}

```

**Hint:** Look up the arrange() documentation with `?arrange` to figure out how to reverse the order of the sort. The examples at the bottom of the screen may be helpful, and you can run it in R if it helps!

- Who had the lowest per capita debt in 2003? 
- How much was the lowest per capita debt in 2003?
- How much was the highest per capita debt in 2018?

### Filtering Data

To print the state with the lowest or highest per capita debt, you can subset with base syntax, which looks something like this:

```{r subset, eval=FALSE}
student_loan_debt[row_number, column_number]
student_loan_debt[row_condition, ]$column_name
```

Or you can subset with the `filter` function from the `tidyverse`, which is a bit easier to read. The `pull` function does the same thing as the `$` sign, which **pulls** a column from a data frame.

```{r subset2, eval=FALSE}
filter(student_loan_debt, row_condition) %>% 
  pull(column_name)
```

**Note:** Another function you'll run into often that works similarly to `pull()` is `select()`. To put it simply, `pull()` returns a single column, while `select()` can pick more than one variable and returns a data frame with all of those columns. The above code returns a single column vector, `column_name`. If you would have used:

```{r subset3, eval=FALSE}
filter(student_loan_debt, row_condition) %>% 
  select(column_name)
```

You would have gotten a data frame that contains one column vector, `column_name`. These two things might appear to be the same at first glance, but over time you'll see they're not! Digression over.

What is a "row_condition" in this case? It's just something that we want to filter on, for example:

```{r filter}
filter(student_loan_debt, per_capita_student_debt < 800)
```

Try writing a `filter` statement to get all states with an average per capita student debt of 5000 or higher in the year 2008. Yes, you can combine multiple criteria - just add a comma and another filtering criteria!
```{r filter2}

```

**Hint:** Your code should look like this: filter(data, condition1, condition2).

Finally, `filter` is great for helping us figure out where the missing values are in our data. 
```{r filter-na}
filter(student_loan_debt, is.na(per_capita_student_debt))
```

Who is missing data in 2017 and 2018? 

### Grouping and Summarizing Data

You might notice that our data is a little awkward to work with right now. We have state-year data instead of just yearly data. One thing that R is great at is helping us come up with groupwise averages, minima, maxima, and more!

For example, here is code to take `student_loan_debt`, group it by year, and then find the maximum per capita debt by year.

```{r group1}
max_debt_by_year <- student_loan_debt %>%
    group_by(year) %>%
    summarize(max_debt = max(per_capita_student_debt))

max_debt_by_year
```

Try calculating the minimum per capita debt by year. Assign it to a new dataframe called `min_debt_by_year` instead of `max_debt_by year`.

**Note**: In order to view the `min_debt_by_year` dataframe after you've created it, type it again in the console to print it.

```{r group2}
min_debt_by_year <- ___ %>%
    group_by(___) %>%
    summarize(___ = min(___))

min_debt_by_year
```

How about the mean per capita debt by year? Let's call this dataframe `student_loan_debt_by_year`, and the variable `per_capita_student_debt`. Write this one from scratch!

```{r group3}

```

What is the minimum and mean per capita debt in 2011?

### Dealing with Missing Data

Notice anything strange about the years 2017 and 2018? The values were NA for everything, even though we had data for most states. This is because NAs are "sticky", which means taking the mean of a vector with NAs makes the output NA. You can get around this with the `na.rm = ` argument in `min()`, `max()`, and `mean()`. Try adding it to the `mean()` function.

```{r group4}

```

**Hint:** Your mean function inside of summarize should look like this: `mean(variable, na.rm = TRUE)`.

What is the mean per capita debt in 2018, excluding Puerto Rico?

## Joining and Plotting Data

Our analysis is close now! One thing to note: we took an average of averages so our per capita estimate may be wrong. We saw that DC had very high debt levels. However, it has a small population compared to the states.

To tackle this, we'll use a population dataset from the same spreadsheet. We clean it with the following code, which is similar to what we did before. Here's the code used to clean the data:

```{r cleanpop, eval=FALSE}
library(tidyverse)
library(readxl)

population <- read_xlsx("data/area_report_by_year.xlsx", sheet = "population", skip = 3)  %>%
  filter(state != "allUS") %>%
  gather(key = year, value = population, -state) %>%
  mutate(year = str_sub(year, 4, 7),
         year = as.numeric(year))

write_csv(population, "population.csv")
```

After running the above code, our population dataset looks like this:

![](images/05_pop.jpg)

The cleaned dataset is `population.csv`. Let's load it:

```{r data2-load}
population <- ___
```

Let's join the population data to our debt data and then weight the data by population.

```{r join}
joined_data <- student_loan_debt %>%
    left_join(population, by = c("state", "year"))

joined_data
```

We essentially use `state` and `year` as ways to link the two dataframes to each other. This is a common functionality in databases (and in SQL), but we can do the same in R!

The joined data looks like this (note the extra column):

![](images/06_joined.jpg)

To reweight, follow the following steps:

1. Use `mutate()` to calculate the total student debt in a state. (pop x debt/person = total debt)

```{r reweight1}
student_loan_debt_by_year_weighted <- ___ %>%
  mutate(___ = ___ * ___) 

student_loan_debt_by_year_weighted
```

2. Use `group_by()` and `summarize()` to calculate the total debt in the US each year and the population of the US each year. Be wary of NAs.

```{r reweight2}
student_loan_debt_by_year_weighted <- ___ %>%
  mutate(___ = ___ * ___) %>% 
  group_by(___) %>%
  summarize(___ = sum(___, na.rm=___),
            ___ = sum(___, na.rm=___)) 

student_loan_debt_by_year_weighted
```

3. Use `mutate()` to calculate the per capita student debt.

```{r reweight3}
student_loan_debt_by_year_weighted <- ___ %>%
  mutate(___ = ___ * ___) %>% 
  group_by(___) %>%
  summarize(___ = sum(___, na.rm=___),
            ___ = sum(___, na.rm=___)) %>% 
  mutate(___ = ___/___)

student_loan_debt_by_year_weighted
```

### Plotting our Estimates

One of the nicest things to do in R is custom visualization. One package that is especially good for plotting and graphs is called `ggplot2`.

Use the following `ggplot2` code to compare your original unweighted estimates in `student_loan_debt_by_year` to the weighted estimates in `student_loan_debt_by_year_weighted`. The unweighted estimates will be in red.

```{r plot}
library(ggplot2)
student_loan_debt_by_year_weighted %>%
  ggplot(aes(x = year, y = per_capita_student_debt)) +
  geom_line() +
  theme_minimal() +
  geom_line(data = student_loan_debt_by_year, color = "red")
```

If you're interested in learning more about `ggplot2`, [R for Data Science](https://r4ds.had.co.nz/data-visualisation.html) has a great chapter on the package.
